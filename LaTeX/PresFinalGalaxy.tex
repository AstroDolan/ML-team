\documentclass{beamer}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[spanish,provide=*]{babel}
% Cargar apacite después de babel para citas autor-año correctas
\usepackage[notocbib]{apacite}

% other packages
\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra, tcolorbox}
\usepackage{graphicx,listings,stackengine}
% Manejo robusto de nombres de archivo con espacios y rutas de imágenes
\usepackage{grffile}
\graphicspath{{pic/}}

\renewcommand{\APACrefbtitle}[2]{#1}       % Muestra solo el título 
\renewcommand{\APACrefYearMonthDay}[3]{#1} % Muestra solo el año (omite mes/día)

\author{Brian Gonzalez, Dylan Jara}
\title{GAX-Kepler: Clasificador de morfología galáctica mediante el uso de redes neuronales convolucionales}
\subtitle{}
\institute{
    Universidad de Santiago de Chile
}
\date{\today}
\usepackage{Ritsumeikan}

% defs
\def\cmd#1{\texttt{\color{red}\footnotesize $\backslash$#1}}
\def\env#1{\texttt{\color{blue}\footnotesize #1}}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{ccnuMainColor}{RGB}{57,64,73}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{halfgray}{gray}{0.55}

\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\bfseries\color{deepblue},
    emphstyle=\ttfamily\color{ccnuMainColor},    % Custom highlighting style
    stringstyle=\color{deepgreen},
    numbers=left,
    numberstyle=\small\color{halfgray},
    rulesepcolor=\color{red!20!green!20!blue!20},
    frame=shadowbox,
}

\renewcommand{\APACrefbtitle}[2]{#1} % Muestra solo el título
\renewcommand{\APACrefYearMonthDay}[3]{#1} % Muestra solo el año
\renewcommand{\APACrefnote}[1]{} % Elimina las notas

\begin{document}

\begin{frame}
    \titlepage
    \vspace*{-0.6cm}
    \begin{figure}
        \begin{center}
                % Ajuste de tamaño más visible y uso de \graphicspath
                \includegraphics[keepaspectratio, width=0.25\textwidth]{Usach S1.png}
        \end{center}
    \end{figure}
\end{frame}

% Restaurar la tabla de contenidos y corregir el problema de 'Referencias32'
\begin{frame}
    \tableofcontents[sectionstyle=show, subsectionstyle=show/shaded/hide]
\end{frame}

%//////////////////////////////////////////////////////%
\section{Introducción} %Dylan%
\subsection{Estado del arte} %Dylan%
\begin{frame}{Estado del arte}
    \begin{itemize}
        \item<1-> Las Máquinas de Soporte Vectorial fueron introducidas por Cortes y Vapnik \cite{cortes1995support} 
        \item<2-> Se volvieron populares en los tardios 90, particularmente en la comunidad de machine learing \cite{vapnik2013nature}.
        \item<3-> Usaremos un ensamble CNN-SVR para clasificar la morfología de las galaxias.
    \end{itemize}
\end{frame}

\begin{frame}{Modelo inicial: CNN clásica}
\begin{itemize}
    \item<1-> Se utilizó una red neuronal convolucional para clasificar imágenes de galaxias.
    \item<2-> El modelo aprende filtros convolucionales fijos a partir de los datos.
    \item<3-> Cada imagen produce una única predicción determinista.
    \medskip
    \item<4->\textbf{Limitación:}\\El modelo no entrega información sobre la incertidumbre de sus predicciones.
    
\end{itemize}

\medskip

\end{frame}

\begin{frame}{Limitaciones del enfoque clásico}
\begin{itemize}
    \item<1-> Las imágenes astronómicas presentan ruido y estructuras difusas.
    \item<2-> Existen casos ambiguos incluso para observadores humanos.
    \item<3-> Una predicción puntual puede ser engañosa en estos casos.
    \medskip
    \item<4->\textbf{Pregunta clave:}
    \textquestiondown Cómo saber cuándo el modelo está realmente seguro de su predicción?
    \end{itemize}
\end{frame}

\begin{frame}{¿Qué es un modelo bayesiano?}
\begin{itemize}
    \item En un modelo bayesiano, los parámetros no son valores fijos.
    \item Cada peso se modela como una distribución de probabilidad.
    \item El modelo aprende tanto el valor esperado como la incertidumbre de los pesos.
\end{itemize}

\medskip
\textbf{Idea central:}
\begin{quote}
El modelo no aprende una única solución, sino un conjunto de soluciones plausibles.
\end{quote}
\end{frame}

\section{Estado del Arte}

\begin{frame}{Estado del Arte: Evolución de la Clasificación}
    La clasificación morfológica ha evolucionado desde la inspección visual hasta el Deep Learning.
    
    \begin{itemize}
        \item \textbf{Dieleman et al. (2015):} El cambio de paradigma. Ganadores del desafío Kaggle Galaxy Zoo, demostraron que las CNNs pueden predecir probabilidades de morfología mejor que los humanos, utilizando rotaciones para invarianza \cite{dieleman2015rotation}.
        
        \item \textbf{Arquitecturas Híbridas (Actualidad):} Modelos recientes combinan la extracción de características profundas con clasificadores robustos como SVM/SVR o Random Forest para mejorar la generalización en datasets ruidosos \cite{huertas2015morphology}.
    \end{itemize}
\end{frame}

%/////////////////////////////////////////////%\
\section{Fundamentos Teóricos: SVR}

\begin{frame}{Support Vector Regression (SVR)}
        A diferencia de la clasificación tradicional, la SVR busca predecir valores continuos (probabilidades).
        
        \begin{itemize}
            \item \textbf{Objetivo:} Encontrar una función $f(x)$ que tenga, a lo sumo, una desviación $\epsilon$ de los objetivos reales $y_i$.
            \item \textbf{Margen de Tolerancia:} Ignora errores menores a $\epsilon$ (zona insensible), lo que la hace muy robusta ante el ruido \cite{drucker1996support}.
            \item \textbf{Kernel Trick:} Permite mapear datos a dimensiones superiores para resolver problemas no lineales \cite{vapnik1995nature}.
        \end{itemize}
\end{frame}
 
%/////////////////////////////////////////////%
\section{Implementación} %Buraian
\subsection{Arquitectura de la red}
\begin{frame}{Arquitectura del Modelo CNN}
\footnotesize
\begin{table}
\centering
\begin{tabular}{l c r}
\toprule
\textbf{Capa (tipo)} & \textbf{Forma de salida} & \textbf{Parámetros} \\
\midrule
Input (Sequential) & $(64, 64, 3)$ & 0 \\

Conv2D (64 filtros) & $(62, 62, 64)$ & 1,792 \\
Batch Normalization & $(62, 62, 64)$ & 256 \\
MaxPooling2D & $(31, 31, 64)$ & 0 \\

Conv2D (128 filtros) & $(29, 29, 128)$ & 73,856 \\
Batch Normalization & $(29, 29, 128)$ & 512 \\
MaxPooling2D & $(14, 14, 128)$ & 0 \\

Conv2D (256 filtros) & $(12, 12, 256)$ & 295,168 \\
Batch Normalization & $(12, 12, 256)$ & 1,024 \\
MaxPooling2D & $(6, 6, 256)$ & 0 \\
\midrule

\bottomrule
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Arquitectura del Modelo CNN II}
\footnotesize
\begin{table}
\centering
\begin{tabular}{l c r}
\toprule
\textbf{Capa (tipo)} & \textbf{Forma de salida} & \textbf{Parámetros} \\
\midrule

GlobalAveragePooling2D & (None, 256) & 0 \\
Dense & (None, 256) & 65,792 \\
Dropout & (None, 256) & 0 \\
Dense (Output) & (None, 37) & 9,509 \\
\midrule
\textbf{Total params} &  & \textbf{447,909} \\
Trainable params &  & 447,013 \\
Non-trainable params &  & 896 \\
\bottomrule
\end{tabular}
\end{table}
\end{frame}


\begin{frame}{Arquitectura de la CNN Bayesiana}
\scriptsize
\centering
\begin{tabular}{l c r}
\toprule
\textbf{Layer (Type)} & \textbf{Output Shape} & \textbf{Param \#} \\
\midrule
Input & (None, 64, 64, 3) & 0 \\

Convolution2DFlipout & (None, 64, 64, 64) & $\sim$3,584 \\
BatchNormalization & (None, 64, 64, 64) & 256 \\
MaxPooling2D & (None, 32, 32, 64) & 0 \\

Convolution2DFlipout & (None, 32, 32, 128) & $\sim$147,712 \\
BatchNormalization & (None, 32, 32, 128) & 512 \\
MaxPooling2D & (None, 16, 16, 128) & 0 \\

Convolution2DFlipout & (None, 16, 16, 256) & $\sim$590,336 \\
BatchNormalization & (None, 16, 16, 256) & 1,024 \\
MaxPooling2D & (None, 8, 8, 256) & 0 \\

GlobalAveragePooling2D & (None, 256) & 0 \\

DenseFlipout & (None, 256) & $\sim$131,584 \\

DenseFlipout (Output) & (None, 37) & $\sim$18,962 \\
\midrule
\textbf{Total parameters} &  & $\sim$893k \\
\bottomrule
\end{tabular}
\end{frame}




\begin{frame}{Arquitectura del Modelo CNN-SVR}
\scriptsize
\centering
\begin{tabular}{l c r}
\toprule
\textbf{Layer (Type)} & \textbf{Output Shape} & \textbf{Param \#} \\
\midrule

Input (Functional) & $(64, 64, 3)$ & 0 \\
Sequential(Sequential) & $(64, 64, 3)$ & 0 \\
Conv2D (64 filtros) & $(64, 64, 64)$ & 1,792 \\
Batch Normalization & $(64, 64, 64)$ & 256 \\
MaxPooling2D & $(32, 32, 64)$ & 0 \\

Conv2D (128 filtros) & $(32, 32, 128)$ & 73,856 \\
Batch Normalization & $(32, 32, 128)$ & 512 \\
MaxPooling2D & $(16, 16, 128)$ & 0 \\

Conv2D (256 filtros) & $(16, 16, 256)$ & 295,168 \\
Batch Normalization & $(16, 16, 256)$ & 1,024 \\
MaxPooling2D & $(8, 8, 256)$ & 0 \\

features = GlobalAveragePooling2D & (None, 256) & 0 \\
Dense (Output) & (None, 37) & 9,509 \\

extractor = Model(in,out(f)) &  &  \\
\midrule
\textbf{Total parameters} &  & $\sim$382k \\
\bottomrule
\end{tabular}
\end{frame}


%/////////////////////////////////////////////%
\section{Entrenamiento del modelo de estudio}




%///////////////////////////////////////////////////%
\section{validación} %Brian%






%/////////////////////////////////////////////%
\section{Conclusiones} %Brian - Dylan
\begin{frame}{Conclusiones}
    \begin{enumerate}
        \item Las CNN son una herramienta poderosa para la clasificación de imágenes
        \item Con ayuda de un buen entendimiento en la teoría del problema, se pueden lograr muy buenos resultados.
        \item La clasificación automática de galaxias puede acelerar significativamente el análisis de grandes conjuntos de datos astronómicos. 
    \end{enumerate}
\end{frame}


%/////////////////////////////////////////////%
\begin{frame}[allowframebreaks]{Referencias}
    \tiny
    \bibliographystyle{apacite}
    \bibliography{PresFinalGalaxy}
\end{frame}

\end{document}