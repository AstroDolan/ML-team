{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71323d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c6d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de velocidad terminal Vs(z)\n",
    "def Vs(z):\n",
    "    Vs_zmin = 0.05  # Velocidad de caída en zmin (m/s)\n",
    "    return Vs_zmin * np.exp(0.024 * z)\n",
    "\n",
    "\n",
    "# Tiempo total de la erupción en segundos (72 horas)\n",
    "tiempo_total_erupcion = 72 * 3600  # 72 horas convertidas a segundos\n",
    "\n",
    "\n",
    "# Definir la función de emisión acumulada de partículas para las 72 horas\n",
    "def Q_acumulado(H, tiempo_total_erupcion):\n",
    "    Q = (H / 0.117)**4.54  # Tasa de emisión basada en la fórmula de Settle\n",
    "    return Q * tiempo_total_erupcion  # Tasa de emisión acumulada para 72 horas\n",
    "\n",
    "\n",
    "# Definir el término fuente modificado con la tasa de emisión acumulada\n",
    "def source_term(H, A, r0, x, y, z, t):\n",
    "    Q_dynamic = Q_acumulado(H, tiempo_total_erupcion)  # Tasa de emisión acumulada\n",
    "    f = 1 / (np.pi * (r0 + z / 8)**2)\n",
    "    S = (A**2 * (1 - z / H) * np.exp(A * (z / H - 1))) / (H * (1 - (1 + A) * np.exp(-A)))\n",
    "    return Q_dynamic * S * f\n",
    "\n",
    "\n",
    "# Condiciones iniciales\n",
    "def initial_condition(x, y, z):\n",
    "    return tf.exp(-0.1 * (x**2 + y**2 + z**2))\n",
    "\n",
    "\n",
    "# Definir la ecuación diferencial parcial de advección-difusión con término temporal\n",
    "def advection_diffusion(c, x, y, z, t, u_x, u_y, u_z, D_xx, D_yy, D_zz, S):\n",
    "    c_x, c_y, c_z = tf.gradients(c, [x, y, z])\n",
    "    c_xx, c_yy, c_zz = tf.gradients(c_x, x)[0], tf.gradients(c_y, y)[0], tf.gradients(c_z, z)[0]\n",
    "    c_t = tf.gradients(c, t)[0]\n",
    "    Vs_value = Vs(z)\n",
    "    return c_t + u_x * c_x + u_y * c_y + Vs_value * c_z - (D_xx * c_xx + D_yy * c_yy + D_zz * c_zz) - S\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417c8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la simulación (modificados según los datos reales del volcán Hudson 1991)\n",
    "x = np.linspace(-10, 10, 50)  # Reducido a 50 puntos\n",
    "y = np.linspace(-10, 10, 50)\n",
    "z = np.linspace(-10, 10, 50)\n",
    "t = np.linspace(0, 10, 50)  # Reducido a 50 puntos\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "X_flatten, Y_flatten, Z_flatten = X.flatten(), Y.flatten(), Z.flatten()\n",
    "\n",
    "\n",
    "# Parámetros actualizados\n",
    "u_x, u_y, u_z = 4.1156, -3.6011, 0.2  # Velocidades del viento en m/s\n",
    "D_xx, D_yy, D_zz = 4000, 4000, 45  # Coeficientes de difusión en m²/s (ajustados)\n",
    "Vs_zmin = 0.05  # Velocidad terminal de caída en zmin en m/s\n",
    "r0 = 400  # Radio del cráter en metros\n",
    "H = 16.0  # Altura máxima de la columna en kilómetros\n",
    "A = 1.5  # Parámetro adimensional para la posición de máxima concentración\n",
    "\n",
    "\n",
    "# Datos de terreno reales\n",
    "def terrain_data():\n",
    "    # Datos de isopacas medidos en terreno\n",
    "    distances = np.array([17841.24, 13819.76, 10555.02, 2110.04, 25231.325, 29586.351, 34549.414, 39088.20])  # En metros\n",
    "    thickness = np.array([0.5, 1.0, 1.5, 0.4, 0.3, 0.2, 0.18, 0.15])  # Espesor de isopacas en metros\n",
    "\n",
    "\n",
    "    # Asumimos que las coordenadas (X, Y) están en el plano y Z es la altura del terreno.\n",
    "    # Vamos a generar datos radiales en el plano.\n",
    "    theta = np.linspace(0, 2 * np.pi, len(distances))\n",
    "    X_terrain = distances * np.cos(theta)\n",
    "    Y_terrain = distances * np.sin(theta)\n",
    "    Z_terrain = np.zeros_like(X_terrain)  # Asumimos que el terreno está plano en Z=0\n",
    "    # Inputs de entrenamiento\n",
    "    inputs_terreno = np.stack([X_terrain, Y_terrain, Z_terrain, np.zeros_like(X_terrain)], axis=-1)\n",
    "    targets_terreno = thickness  # Los valores de isopacas como objetivo\n",
    "    return inputs_terreno, targets_terreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af16f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar datos de entrenamiento originales y datos de terreno\n",
    "T_flatten = np.full(X_flatten.shape, 0)  # Tiempo inicial para las condiciones iniciales\n",
    "inputs_sinteticos = np.stack([X_flatten, Y_flatten, Z_flatten, T_flatten], axis=-1)\n",
    "targets_sinteticos = initial_condition(X_flatten, Y_flatten, Z_flatten).numpy()\n",
    "\n",
    "\n",
    "# Datos de terreno\n",
    "inputs_terreno, targets_terreno = terrain_data()\n",
    "\n",
    "\n",
    "# Combinar ambos conjuntos de datos\n",
    "inputs_combinados = np.vstack([inputs_sinteticos, inputs_terreno])\n",
    "targets_combinados = np.concatenate([targets_sinteticos.flatten(), targets_terreno])\n",
    "\n",
    "\n",
    "# Ajuste de la función de pérdida personalizada\n",
    "def custom_loss(y_true, y_pred):\n",
    "    initial_condition_penalty = tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "    return 0.1 * initial_condition_penalty + tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf03afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\djara\\Documents\\ML-team\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Modelo de red neuronal con softplus para concentraciones positivas\n",
    "model = models.Sequential([\n",
    "    layers.Dense(50, activation='tanh', input_shape=(4,)),\n",
    "    layers.Dense(50, activation='tanh'),\n",
    "    layers.Dense(50, activation='tanh'),  # Capa adicional\n",
    "    layers.Dense(1, activation='softplus')  # Softplus para evitar concentraciones negativas\n",
    "])\n",
    "\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3504a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de la red neuronal con más épocas\n",
    "model.fit(inputs_combinados, targets_combinados, epochs=500, verbose=1, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b77017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función export_to_geotiff para guardar predicciones como archivo GeoTIFF\n",
    "def export_to_geotiff(data, filename, transform):\n",
    "    with rasterio.open(\n",
    "        filename, 'w',\n",
    "        driver='GTiff',\n",
    "        height=data.shape[0],\n",
    "        width=data.shape[1],\n",
    "        count=1,\n",
    "        dtype=data.dtype,\n",
    "        crs='EPSG:32718',  # Proyección UTM Zona 18S\n",
    "        transform=transform\n",
    "    ) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "\n",
    "# Transformación geoespacial (ajustar a la región del volcán Hudson)\n",
    "x_min, y_max = 640000, 4810000  # Coordenadas UTM del área del Volcán Hudson (aproximadas)\n",
    "pixel_size = 100  # Tamaño del píxel en metros\n",
    "\n",
    "\n",
    "# Crear la transformación desde el origen\n",
    "transform = from_origin(x_min, y_max, pixel_size, pixel_size)\n",
    "\n",
    "\n",
    "# Predicción y exportación de resultados en formato GeoTIFF\n",
    "for time in [0, 10]:  # Puedes ajustar los tiempos según lo necesites\n",
    "    prediction = model.predict(np.stack([X_flatten, Y_flatten, Z_flatten, np.full(X_flatten.shape, time)], axis=-1)).reshape(50, 50, 50)\n",
    "    output_filename = f\"prediccion_t{time}.tif\"\n",
    "    export_to_geotiff(prediction[:, :, 25], output_filename, transform)\n",
    "    print(f\"Archivo GeoTIFF '{output_filename}' exportado correctamente.\")\n",
    "\n",
    "\n",
    "# Guardar los resultados de entrenamiento en archivos CSV o Excel si es necesario\n",
    "r = np.sqrt(X_flatten**2 + Y_flatten**2 + Z_flatten**2)\n",
    "df = pd.DataFrame({'Distancia': r, 'Concentración': prediction.flatten()})\n",
    "df.to_csv('concentracion_vs_distancia.csv', index=False)\n",
    "df.to_excel('concentracion_vs_distancia.xlsx', index=False)\n",
    "print(\"Predicciones exportadas y resultados guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción con la red entrenada en diferentes momentos\n",
    "times_to_predict = [0, 2, 4, 6, 8, 10]  # Diferentes tiempos para predecir\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "\n",
    "for i, time in enumerate(times_to_predict):\n",
    "    inputs_time = np.stack([X_flatten, Y_flatten, Z_flatten, np.full(X_flatten.shape, time)], axis=-1)\n",
    "    predictions = model.predict(inputs_time).reshape((50, 50, 50))\n",
    "\n",
    "\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.contourf(X[:, :, 25], Y[:, :, 25], predictions[:, :, 25], levels=50, cmap='viridis')\n",
    "    ax.set_title(f'Predicción con PINN en t={time}')\n",
    "    ax.set_xlabel('X (m)')\n",
    "    ax.set_ylabel('Y (m)')\n",
    "    plt.colorbar(ax.contourf(X[:, :, 25], Y[:, :, 25], predictions[:, :, 25], levels=50, cmap='viridis'), ax=ax)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0302cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar predicciones de diferentes tiempos\n",
    "for time in times_to_predict:\n",
    "    prediction = model.predict(np.stack([X_flatten, Y_flatten, Z_flatten, np.full(X_flatten.shape, time)], axis=-1)).reshape(50, 50, 50)\n",
    "    output_filename = f\"prediccion_t{time}.tif\"\n",
    "    export_to_geotiff(prediction[:, :, 25], output_filename, transform)\n",
    "    print(f\"Archivo GeoTIFF '{output_filename}' exportado correctamente.\")\n",
    "\n",
    "\n",
    "# Guardar resultados en CSV\n",
    "r = np.sqrt(X_flatten**2 + Y_flatten**2 + Z_flatten**2)\n",
    "df = pd.DataFrame({'Distancia': r, 'Concentración': predictions.flatten()})\n",
    "df.to_csv('concentracion_vs_distancia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a182803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de datos de entrenamiento con la misma escala de color\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cont1 = plt.contourf(X[:, :, 25], Y[:, :, 25], targets.reshape(50, 50, 50)[:, :, 25], levels=50, cmap='viridis')\n",
    "plt.colorbar(cont1)\n",
    "plt.title('Datos de Entrenamiento (Condición Inicial)')\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "\n",
    "\n",
    "# Gráfico de predicción con PINN con la misma escala de color\n",
    "plt.subplot(1, 2, 2)\n",
    "cont2 = plt.contourf(X[:, :, 25], Y[:, :, 25], predictions[:, :, 25], levels=50, cmap='viridis')\n",
    "plt.colorbar(cont2)\n",
    "plt.title('Predicción con PINN')\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la distancia radial al cráter\n",
    "r = np.sqrt(X_flatten**2 + Y_flatten**2 + Z_flatten**2)\n",
    "\n",
    "\n",
    "# Guardar los resultados en un archivo .csv en el directorio actual\n",
    "df = pd.DataFrame({'Distancia': r, 'Concentración': predictions.flatten()})\n",
    "df.to_csv('concentracion_vs_distancia.csv', index=False)\n",
    "\n",
    "\n",
    "# Gráfico adicional: Concentración vs Distancia\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(r, predictions.flatten(), alpha=0.5)\n",
    "plt.xlabel('Distancia al Cráter (m)')\n",
    "plt.ylabel('Concentración de Ceniza')\n",
    "plt.title('Concentración de Ceniza en Función de la Distancia al Cráter')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calcular el área bajo la curva para diferentes valores de concentración (isopacas)\n",
    "isopacas = np.linspace(predictions.min(), predictions.max(), num=10)  # Dividir en 10 niveles\n",
    "areas = []\n",
    "\n",
    "\n",
    "for iso in isopacas:\n",
    "    # Calcular el área donde la concentración es mayor que el nivel de isopaca\n",
    "    area = np.sum(predictions >= iso) * (x[1] - x[0]) * (y[1] - y[0])  # Aproximar el área\n",
    "    areas.append(area)\n",
    "\n",
    "\n",
    "# Ajuste del área total basado en la estimación conocida de 150,000 km²\n",
    "total_area = 150000 * 1e6  # 150,000 km² a m²\n",
    "areas_normalizadas = [area / np.sum(areas) * total_area for area in areas]\n",
    "\n",
    "\n",
    "# Graficar el área versus isopacas ajustadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(isopacas, areas_normalizadas, marker='o')\n",
    "plt.xlabel('Concentración de Ceniza (isopacas)')\n",
    "plt.ylabel('Área Cubierta (m²)')\n",
    "plt.title('Área Cubierta por Diferentes Niveles de Isopacas (Ajustada)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
